---
title: A site server with live reload
date: 2024-03-05
layout: post
lang: en
tags: [golang, project]
draft: true
---
#+OPTIONS: toc:nil num:1
#+LANGUAGE: en

The core of my static site generator is the ~build~ command: take some input files, process them ---render templates, convert other markup formats into HTML--- and write the output for serving to the web. This is where I started with ~jorge~, not only because it was core functionality but because I needed to see the org-mode output as early as possible, to learn if I could expect this project to ultimately replace my Jekyll setup.

You could say that I had a working static site generator as soon as the ~build~ command was done, but for it to be minimally useful I needed some facility to preview a site while working on it: the ~serve~ command. It could be as simple as running a local file server of the ~build~ output, but ideally it would also watch for changes in the source files and live-reload the browser tabs looking at them.

I was aiming for more than the basics here because ~serve~ was the only non-trivial command of the project: the one with the most Go learning potential ---and the most fun. For similar reasons, I wanted to tackle it as early as possible: since it wasn't immediately obvious how I would implement it, it was here where unknown-unknowns and blockers were most likely to come up.
Once ~build~ and ~serve~ were out of the way, I'd be almost done with the project, the rest being nice-to-have features and UX improvements.

The beauty of the ~serve~ command was that I could start with a naive implementation and iterate towards the ideal one, keeping a usable command at every step. Below is a summary of that process.

*** A basic file server

At its simplest, the ~serve~ command consisted of building the site once and serving the target directory with a local server. The standard ~net/http~ package provides [[https://pkg.go.dev/net/http#FileServer][facilities]] for local file servers:

#+begin_src go
func Serve(config config.Config) error {
	// load and build the project
	if err := site.Build(config); err != nil {
		return err
	}

	// mount the target dir on a local file server
	fs := http.FileServer(http.Dir(config.TargetDir))
	http.Handle("/", fs)

	fmt.Println("server listening at http://localhost:4001/")
	return http.ListenAndServe(":4001", nil)
}
#+end_src

This only required a minor change (based in [[https://stackoverflow.com/a/57281956/993769][this]] StackOverflow answer) to allow omitting the ~.html~ suffix from URLs:

#+begin_src go
type HTMLFileSystem struct {
	dirFS http.Dir
}

func (htmlFS HTMLFileSystem) Open(name string) (http.File, error) {
	// Try name as supplied
	f, err := htmlFS.dirFS.Open(name)
	if os.IsNotExist(err) {
		// Not found, try with .html
		if f, err := htmlFS.dirFS.Open(name + ".html"); err == nil {
			return f, nil
		}
	}
	return f, err
}
#+end_src

The ~HTMLFileSystem~ above wraps the standard ~http.Dir~ to look for a ~.html~ file when the filename requested isn't found so, for instance, ~target/blog/hello.html~ will be served when receiving a request for ~/blog/hello~. The server setup thus changed to:

#+begin_src diff
-	fs := http.FileServer(HTMLFileSystem{http.Dir(config.TargetDir)})
+	fs := http.FileServer(http.Dir(config.TargetDir))
	http.Handle("/", fs)

	fmt.Println("server listening at http://localhost:4001/")
	return http.ListenAndServe(":4001", nil)
#+end_src

*** Watching for changes
As a next step, instead of building the site once before running the server I wanted the command to watch the project source directory and trigger new builds every time a file changed. I found the [[https://github.com/fsnotify/fsnotify][fsnotify]] library for this exact purpose; the fact that both Hugo and gojekyll listed it in their dependencies suggested that it was a reasonable choice for the job.

Following [[https://github.com/fsnotify/fsnotify/blob/c94b93b0602779989a9af8c023505e99055c8fe5/README.md#usage][an example]] from the fsnotify documentation, I created a watcher and a goroutine that triggered a ~site.Build~ call every time a file change event was received:

#+begin_src go
func runWatcher(config *config.Config) {
	watcher, _ := fsnotify.NewWatcher()
	defer watchProjectFiles(watcher, config)

	go func() {
		for event := range watcher.Events {
			fmt.Printf("file %s changed\n", event.Name)

			// src directories could have changed
			// so project files need to be re-watched every time
			watchProjectFiles(watcher, config)
			site.Build(*config)
		}
	}()
}
#+end_src

Then made the watcher look at changes in the project ~src~ directory:

#+begin_src go
func watchProjectFiles(watcher *fsnotify.Watcher, config *config.Config) {
	// fsnotify watches all files within a dir, but non-recursively
	// this walks through the source dir
	// adding watches for each found subdir
	filepath.WalkDir(config.SrcDir, func(path string, entry fs.DirEntry, err error) error {
		if entry.IsDir() {
			watcher.Add(path)
		}
		return nil
	})
}
#+end_src

*** Build optimizations
At this point I had a useful file server, always responding with the most recent version of the site. But the responsiveness of the ~serve~ command was less than ideal: the entire website had to be processed and copied to the target for any small edit I made on a source file.

I wanted to attempt some performance improvements to the build process, but without introducing much complexity: instead of adding the structure to support incremental or conditional builds, I wanted to try first to keep building the entire site on every change, only faster.

The first cheap optimization was obvious from looking at the command output: most of the work was copying static assets (e.g. images, static CSS files, etc.). So I changed the ~site.Build~ implementation to optionally create links instead of copying files.

The next thing I wanted to try was to process source files work concurrently. The logic for creating target directories and rendering files was handled by an internal method:

#+begin_src go
func (site *site) build() error {
	// clear previous target contents
	os.RemoveAll(site.Config.TargetDir)

	// walk the source directory, creating directories and files at the target dir
	return filepath.WalkDir(site.Config.SrcDir, func(path string, entry fs.DirEntry, err error) error {
		subpath, _ := filepath.Rel(site.Config.SrcDir, path)
		targetPath := filepath.Join(site.Config.TargetDir, subpath)

		// if it's a directory, just create the same at the target
		if entry.IsDir() {
			return os.MkdirAll(targetPath, FILE_RW_MODE)
		}

		// if it's a file render or copy it at the target
		return site.buildFile(path, targetPath)
	})
}
#+end_src

This ~site.build~ method walks the source file tree, recreating directories in the target. For non-directory files, it calls another method, ~site.buildFile~, to do the actual processing (rendering templates, converting markdown and org-mode syntax to HTML, "smartifying" quotes, and writing the results to the target files). I wanted the calls to ~site.buildFile~ offloaded to a pool of workers; I found the facilities I needed in a couple of [[https://gobyexample.com/][Go by Example]] entries:

#+begin_src go
// Runs a pool of workers to build files. Returns a channel
// to send the paths of files to be built and a WaitGroup
// to wait them to finish processing.
Create a channel to send paths to build and a worker pool to handle them concurrently
func spawnBuildWorkers(site *site) (*sync.WaitGroup, chan string) {
	var wg sync.WaitGroup
	files := make(chan string, 20)

	for range runtime.NumCPU() {
		wg.Add(1)
		go func(files <-chan string) {
			defer wg.Done()
			for path := range files {
				site.buildFile(path)
			}
		}(files)
	}
	return &wg, files
}
#+end_src

The function above creates a buffered channel to receive source file paths, and a worker pool with the size of the amount of CPU cores. Each worker registers itself on a ~WaitGroup~ that can be used by callers to block until all workers finish their work.

Then I just needed to adapt the ~build~ function to spawn the workers and send them  file paths through the channel, instead of processing them sequentially:

#+begin_src diff
func (site *site) build() error {
	// clear previous target contents
	os.RemoveAll(site.Config.TargetDir)

+	wg, files := spawnBuildWorkers(site)
+	defer wg.Wait()
+	defer close(files)

	// walk the source directory, creating directories and files at the target dir
	return filepath.WalkDir(site.config.SrcDir, func(path string, entry fs.DirEntry, err error) error {
		subpath, _ := filepath.Rel(site.Config.SrcDir, path)
		targetPath := filepath.Join(site.Config.TargetDir, subpath)

		// if it's a directory, just create the same at the target
		if entry.IsDir() {
			return os.MkdirAll(targetPath, FILE_RW_MODE)
		}

-		// if it's a file render or copy it at the target
-		return site.buildFile(path, targetPath)
+		// if it's a file send the path to a worker
+		// to render or copy it at the target
+		files <- path
+		return nil
	})
}
#+end_src

the ~close(files)~ call informs the workers that no more work will be sent, and ~wg.Wait()~ blocks execution until all pending work is finished.

I was very satisfied to see a sequential piece of code turned into a concurrent one with minimal structural changes, without affecting callers of the function I updated. In other languages, a similar process would have required me to add ~async~ and ~await~ statements all over the place.

*** Live reload

- intro sse (vs ws)
- sse boilerplate

#+begin_src diff
	fs := http.FileServer(HTMLFileSystem{http.Dir(config.TargetDir)})
	http.Handle("/", fs)
+	http.Handle("/_events/", ServerEventsHandler)
#+end_src

#+begin_src go
func ServerEventsHandler (res http.ResponseWriter, req *http.Request) {
	res.Header().Set("Content-Type", "text/event-stream")
	res.Header().Set("Connection", "keep-alive")
	res.Header().Set("Cache-Control", "no-cache")
	res.Header().Set("Access-Control-Allow-Origin", "*")

	for {
		select {
		case <-time.After(5 * time.Second):
			// send an event to the connected client.
			// data\n\n just means send an empty, unnamed event
			fmt.Fprint(res, "data\n\n")
			res.(http.Flusher).Flush()
		case <-req.Context().Done():
			// client connection closed
			return
		}
	}
}
#+end_src

The code above will send an empty event every 5 seconds to clients connected to the ~/_events/~ endpoint. After some trial-and-error, I arrived to the following JavaScript snippet for the client side:

#+begin_src html
<script type="text/javascript">
var eventSource;

function newSSE() {
  console.log("connecting to server events");
  eventSource = new EventSource('http://localhost:4001/_events/');

  // when the server sends an event, refresh the page
  eventSource.onmessage = function () {
    location.reload()
  };

  // close connection before refreshing the page
  window.onbeforeunload = function() {
    eventSource.close();
  }

  // on errors disconnect and attempt reconnection after a delay
  // this handles server restarting, laptop sleeping, etc.
  eventSource.onerror = function (event) {
    console.error('an error occurred:', event);
    eventSource.close();
    setTimeout(newSSE, 5000)
  };
}

newSSE();
</script>
  #+end_src

Clients will establish an [[https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events][EventSource]] connection through the ~/_events/~ endpoint, and reload the window whenever a server-sent event arrives. I updated the ~site.buildFile~ logic to inject this script in the header of every HTML file written to the target directory.

So far I had a working events handler and clients connecting to it. I just needed to update the handler to only send events after site rebuilds triggered by the fsnotify watcher. I couldn't just use a channel to connect both components since every rebuild event needed to be broadcast to all connected clients (there could be more than one open tab at any given moment). I introduced an ~EventBroker~ [fn:1]struct for that purpose, with this API (see the full implementation [[https://github.com/facundoolano/jorge/blob/567db560f511b11492b85cf4f72b51599e8e3a3d/commands/serve.go#L175-L238][here]]):

#+begin_src go
// The event broker mediates between the file watcher
// that publishes site rebuild events
// and the clients listening for them to refresh the browser
type EventBroker struct

func newEventBroker() *EventBroker

// Adds a subscription to this broker events
// returning a subscriber id (useful for unsubscribing)
// and a channel where events will be delivered.
func (broker *EventBroker) subscribe() (uint64, <-chan string)

// Remove the subscriber with the given id from the broker,
// closing its associated channel.
func (broker *EventBroker) unsubscribe(id uint64)

// Publish an event to all the broker subscribers.
func (broker *EventBroker) publish(event string)
#+end_src

The events handler now needed to create a subscription on every client connection, to forward rebuild events through it:

#+begin_src diff
-func ServerEventsHandler (res http.ResponseWriter, req *http.Request) {
+func makeServerEventsHandler(broker *EventBroker) http.HandlerFunc {
+	return func(res http.ResponseWriter, req *http.Request) {
		res.Header().Set("Content-Type", "text/event-stream")
		res.Header().Set("Connection", "keep-alive")
		res.Header().Set("Cache-Control", "no-cache")
		res.Header().Set("Access-Control-Allow-Origin", "*")

+		id, events := broker.subscribe()
		for {
			select {
-			case <-time.After(5 * time.Second):
+			case <-events:
				// send an event to the connected client.
				// data\n\n just means send an empty, unnamed event
				fmt.Fprint(res, "data\n\n")
				res.(http.Flusher).Flush()
			case <-req.Context().Done():
				// client connection closed
+				broker.unsubscribe(id)
				return
			}
		}
	}
}
#+end_src

The watcher, in turn, had to publish an event after every rebuild:

#+begin_src diff
-func runWatcher(config *config.Config) {
+func runWatcher(config *config.Config) *EventBroker {
	watcher, _ := fsnotify.NewWatcher()
	defer watchProjectFiles(watcher, config)
+	broker := newEventBroker()

	go func() {
		for event := range watcher.Events {
		fmt.Printf("file %s changed\n", event.Name)

		// new src directories could be triggering this event
		// so project files need to be re-added every time
		watchProjectFiles(watcher, config)
		site.Build(*config)
+		broker.publish("rebuild")
		}
	}()
+	return broker
}
#+end_src


*** Handling event bursts

The code above worked, but not always. Some times, a file change would trigger a browser refresh to a 404 page, as if the new target file wasn't yet written. This was a consequence of single file changes producing many write events, and <it's mentioned in the fsnotify documentation. The solution (also suggested in the doc [LINK]) is to de-duplicate events by adding a delay between event arrival and response. <time.AfterFunc [LINK] helps here


#+begin_src diff
func runWatcher(config *config.Config) *EventBroker {
	watcher, _ := fsnotify.NewWatcher()
-	defer watchProjectFiles(watcher, config)
	broker := newEventBroker()

+	rebuildAfter := time.AfterFunc(0, func() {
+		watchProjectFiles(watcher, config)
+		site.Build(*config)
+		broker.publish("rebuild")
+	})

	go func() {
		for event := range watcher.Events {
			fmt.Printf("file %s changed\n", event.Name)

-			watchProjectFiles(watcher, config)
-			site.Build(*config)
-			broker.publish("rebuild")
+			// Schedule a rebuild to trigger after a delay.
+			// If there was another one pending it will be canceled.
+			rebuildAfter.Stop()
+			rebuildAfter.Reset(100 * time.Millisecond)
		}
	}()
	return broker
}
#+end_src

** Notes

[fn:1] I'm not sure if "broker" is semantically correct in this context, since there's a single event type and is sent to all subscribers. "Broadcaster" is probably more correct, but sounds worse.
