---
title: A site server with live reload
date: 2024-03-05
layout: post
lang: en
tags: [golang, project]
draft: true
---
#+OPTIONS: toc:nil num:1
#+LANGUAGE: en

The core of the static site generator is the ~build~ command: take some input files, process them ---render templates, convert other markup formats into HTML--- and write the output for serving to the web. This is where I started with ~jorge~, not only because it was core functionality but because I needed to see the org-mode output as early as possible to learn if I could expect this project to ultimately replace my Jekyll setup.

You could say that I had a working static site generator as soon as the ~build~ command was done, but for it to be minimally useful I needed some facility to preview a site while working on it: a ~serve~ command. It could be as simple as running a local file server of the ~build~ output files, but ideally I it would also watch for changes and live-reload the browser tabs looking at them.

I was aiming for more than the basics here because ~serve~ was the only non-trivial command I had planned for: the one with the most Go learning potential ---and the most fun. For similar reasons, I wanted to tackle it as early as possible: since it wasn't immediately obvious how I would implement it, it was here where unknown-unknowns and blockers were most likely to come up.
With ~build~ and ~serve~ out of the way, I'd be almost done with the project, the rest being nice-to-have features and UX improvements.

The beauty of the ~serve~ command was that I could start with the most naive implementation and iterate towards the ideal one, keeping a usable command at every step. Below is a summary of that process.

*** A basic file server

The minimum viable implementation of the ~serve~ command consisted in rendering the site by calling ~site.Build(config)~ and serving the target site directory with a local server. Go's standard ~net/http~ already provides facilities for local file servers:

#+begin_src go
func Serve(config config.Config) error {
	// load and build the project
	if err := site.Build(config); err != nil {
		return err
	}

	// serve target with file server
	fs := http.FileServer(http.Dir(config.TargetDir))
	http.Handle("/", fs)

	fmt.Println("server listening at http://localhost:4001/")
	return http.ListenAndServe(":4001", nil)
}
#+end_src

This only required a minor changed (which I based on [[https://stackoverflow.com/a/57281956/993769][this]] StackOverflow answer) to allow request urls to omit the ~.html~ suffix so the local server behaved as I expected a production web server would:

#+begin_src go
type HTMLFileSystem struct {
	dirFS http.Dir
}

func (htmlFS HTMLFileSystem) Open(name string) (http.File, error) {
	// Try name as supplied
	f, err := htmlFS.dirFS.Open(name)
	if os.IsNotExist(err) {
		// Not found, try with .html
		if f, err := htmlFS.dirFS.Open(name + ".html"); err == nil {
			return f, nil
		}
	}
	return f, err
}
#+end_src

The ~HTMLFileSystem~ above wraps the standard ~http.Dir~ optionally looking for e.g. ~target/blog/hello.html~ when the URL requests for ~/blog/hello~. The server setup thus changed to:

#+begin_src diff
-	fs := http.FileServer(HTMLFileSystem{http.Dir(config.TargetDir)})
+	fs := http.FileServer(http.Dir(config.TargetDir))
	http.Handle("/", fs)

	fmt.Println("server listening at http://localhost:4001/")
	return http.ListenAndServe(":4001", nil)
#+end_src

*** Watching for changes
The obvious next step was to, instead of building the site once before starting the server, watching the project source directory and trigger new site builds every time a file change was detected.

I found the [[https://github.com/fsnotify/fsnotify][fsnotify]] library for this exact purpose; the fact that both Hugo and gojekyll listed it in their dependencies hinted to me that it was a reasonable choice for job.

Following the [[https://github.com/fsnotify/fsnotify#usage][example]] in the documentation, I created a watcher and a goroutine that reacted with a ~site.Build~ call to every incoming event:

#+begin_src go
func runWatcher(config *config.Config) {
	watcher, _ := fsnotify.NewWatcher()
	defer watchProjectFiles(watcher, config)

	go func() {
		for event := range watcher.Events {
			fmt.Printf("file %s changed\n", event.Name)

			// new src directories could be triggering this event
			// so project files need to be re-added every time
			watchProjectFiles(watcher, config)
			site.Build(*config)
		}
	}()
}
#+end_src

Then made the watcher look at changes in the project ~src~ directory:

#+begin_src go
func watchProjectFiles(watcher *fsnotify.Watcher, config *config.Config) {
	// fsnotify watches all files within a dir, but non-recursively
	// this walks through the src dir and adds watches for each found directory
	filepath.WalkDir(config.SrcDir, func(path string, entry fs.DirEntry, err error) error {
		if entry.IsDir() {
			watcher.Add(path)
		}
		return nil
	})
}
#+end_src

*** Build optimizations
At this point the file server was useful, always responding with the most recent version of the site. But the responsiveness of the command was less than ideal: the entire website had to be processed and copied to the target for every file save in the source.

I wanted to make some performance improvements to this process, but without adding much code complexity: instead of getting into incremental or conditional builds, I wanted to keep building the entire site on very change, only faster.

The first cheap optimization was obvious from looking at the command output: most of the work was copying static assets (e.g. images, static CSS files, etc.). So I changed the ~site.Build~ implementation to optionally create links instead of copying files.

The next thing I wanted to try was to process source files work concurrently. The logic of the target building was handled by a method from an internal ~site~ struct:

#+begin_src go
func (site *site) build() error {
	// clear previous target contents
	os.RemoveAll(site.Config.TargetDir)

	// walk the source directory, creating directories and files at the target dir
	return filepath.WalkDir(site.Config.SrcDir, func(path string, entry fs.DirEntry, err error) error {
		subpath, _ := filepath.Rel(site.Config.SrcDir, path)
		targetPath := filepath.Join(site.Config.TargetDir, subpath)

		// if it's a directory, just create the same at the target
		if entry.IsDir() {
			return os.MkdirAll(targetPath, FILE_RW_MODE)
		}

		// if it's a file render or copy it at the target
		return site.buildFile(path, targetPath)
	})
}
#+end_src

The ~build~ method walks the source file tree, recreating directories in the target. For non-directory files, it delegates the actual file processing (rendering templates, converting markdown and org-mode syntax to HTML, "smartifying" quotes, and copying the results to the target files) to another internal method: ~site.buildFile~. I wanted this one to run in a worker pool; I found the facilities I needed in a couple of [[https://gobyexample.com/][Go by Example]] entries:

#+begin_src go
// Create a channel to send paths to build and a worker pool to handle them concurrently
func spawnBuildWorkers(site *site) (*sync.WaitGroup, chan string) {
	var wg sync.WaitGroup
	files := make(chan string, 20)

	for range runtime.NumCPU() {
		wg.Add(1)
		go func(files <-chan string) {
			defer wg.Done()
			for path := range files {
				site.buildFile(path)
			}
		}(files)
	}
	return &wg, files
}
#+end_src

The function above creates a buffered channel to receive source file paths, and a worker pool of the size of the available CPU cores. Each worker registers itself on a ~WaitGroup~ that can be used by callers to block until all workers finish their work.

Then, it was just a matter of creating the workers and sending the filepaths through the channel instead of building the files sequentially:

#+begin_src diff
func (site *site) build() error {
	// clear previous target contents
	os.RemoveAll(site.Config.TargetDir)

+	wg, files := spawnBuildWorkers(site)
+	defer wg.Wait()
+	defer close(files)

	// walk the source directory, creating directories and files at the target dir
	return filepath.WalkDir(site.config.SrcDir, func(path string, entry fs.DirEntry, err error) error {
		subpath, _ := filepath.Rel(site.Config.SrcDir, path)
		targetPath := filepath.Join(site.Config.TargetDir, subpath)

		// if it's a directory, just create the same at the target
		if entry.IsDir() {
			return os.MkdirAll(targetPath, FILE_RW_MODE)
		}

-		// if it's a file render or copy it at the target
-		return site.buildFile(path, targetPath)
+		// if it's a file send the path to a worker
+		// to render or copy it at the target
+		files <- path
+		return nil
	})
}
#+end_src

The ~defer close(files)~ closes the channel to inform the workers that no more work will be sent, and the ~defer wg.Wait()~ blocks until all finish processing what they read from the channel.

I loved that I could turn a sequential piece of code into a concurrent one with minimal structural changes, without touching calling sites of the affected function. In other languages, a similar process would have required me to add ~async~ and ~await~ statements to half of the codebase.

*** Live reload

- intro sse (vs ws)
- sse boilerplate

#+begin_src diff
	fs := http.FileServer(HTMLFileSystem{http.Dir(config.TargetDir)})
	http.Handle("/", fs)
+	http.Handle("/_events/", ServerEventsHandler)
#+end_src

#+begin_src go
func ServerEventsHandler (res http.ResponseWriter, req *http.Request) {
	res.Header().Set("Content-Type", "text/event-stream")
	res.Header().Set("Connection", "keep-alive")
	res.Header().Set("Cache-Control", "no-cache")
	res.Header().Set("Access-Control-Allow-Origin", "*")

	for {
		select {
		case <-time.After(5 * time.Second):
			// send an event to the connected client.
			// data\n\n just means send an empty, unnamed event
			fmt.Fprint(res, "data\n\n")
			res.(http.Flusher).Flush()
		case <-req.Context().Done():
			// client connection closed
			return
		}
	}
}
#+end_src

- client boilerplate

#+begin_src javascript
var eventSource;

function newSSE() {
  console.log("connecting to server events");
  eventSource = new EventSource('http://localhost:4001/_events/');

  // when the server sends an event, refresh the page
  eventSource.onmessage = function () {
    location.reload()
  };

  // close connection before refreshing the page
  window.onbeforeunload = function() {
    eventSource.close();
  }

  // on errors disconnect and attempt reconnection after a delay
  // this handles server restarting, laptop sleeping, etc.
  eventSource.onerror = function (event) {
    console.error('an error occurred:', event);
    eventSource.close();
    setTimeout(newSSE, 5000)
  };
}

newSSE();
  #+end_src

- event broker
  - explain need
  - is this name right?
  - show api + link implementation
    see the full implementation [[https://github.com/facundoolano/jorge/blob/567db560f511b11492b85cf4f72b51599e8e3a3d/commands/serve.go#L175-L238][here]]

#+begin_src go
// The event broker mediates between the file watcher
// that publishes site rebuild events
// and the clients listening for them to refresh the browser
type EventBroker struct

func newEventBroker() *EventBroker

// Adds a subscription to this broker events
// returning a subscriber id (useful for unsubscribing)
// and a channel where events will be delivered.
func (broker *EventBroker) subscribe() (uint64, <-chan string)

// Remove the subscriber with the given id from the broker,
// closing its associated channel.
func (broker *EventBroker) unsubscribe(id uint64)

// Publish an event to all the broker subscribers.
func (broker *EventBroker) publish(event string)


#+end_src
  - show updated handler
#+begin_src diff
-func ServerEventsHandler (res http.ResponseWriter, req *http.Request) {
+func makeServerEventsHandler(broker *EventBroker) http.HandlerFunc {
+	return func(res http.ResponseWriter, req *http.Request) {
		res.Header().Set("Content-Type", "text/event-stream")
		res.Header().Set("Connection", "keep-alive")
		res.Header().Set("Cache-Control", "no-cache")
		res.Header().Set("Access-Control-Allow-Origin", "*")

+		id, events := broker.subscribe()
		for {
			select {
-			case <-time.After(5 * time.Second):
+			case <-events:
				// send an event to the connected client.
				// data\n\n just means send an empty, unnamed event
				fmt.Fprint(res, "data\n\n")
				res.(http.Flusher).Flush()
			case <-req.Context().Done():
				// client connection closed
+				broker.unsubscribe(id)
				return
			}
		}
	}
}
#+end_src
  - show updated watcher

#+begin_src diff
-func runWatcher(config *config.Config) {
+func runWatcher(config *config.Config) *EventBroker {
	watcher, _ := fsnotify.NewWatcher()
	defer watchProjectFiles(watcher, config)
+	broker := newEventBroker()

	go func() {
		for event := range watcher.Events {
		fmt.Printf("file %s changed\n", event.Name)

		// new src directories could be triggering this event
		// so project files need to be re-added every time
		watchProjectFiles(watcher, config)
		site.Build(*config)
+		broker.publish("rebuild")
		}
	}()
+	return broker
}
#+end_src


** Preventing bursts

#+begin_src diff
func runWatcher(config *config.Config) *EventBroker {
	watcher, _ := fsnotify.NewWatcher()
-	defer watchProjectFiles(watcher, config)
	broker := newEventBroker()

+	rebuildAfter := time.AfterFunc(0, func() {
+		watchProjectFiles(watcher, config)
+		site.Build(*config)
+		broker.publish("rebuild")
+	})

	go func() {
		for event := range watcher.Events {
			fmt.Printf("file %s changed\n", event.Name)

-			watchProjectFiles(watcher, config)
-			site.Build(*config)
-			broker.publish("rebuild")
+			// Schedule a rebuild to trigger after a delay.
+			// If there was another one pending it will be canceled.
+			rebuildAfter.Stop()
+			rebuildAfter.Reset(100 * time.Millisecond)
		}
	}()
	return broker
}
#+end_src
